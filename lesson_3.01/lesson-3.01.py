"""
Конспект занятия № 3.01
"Введение в Машинное обучение"
"""
# Машинное обучение

"""
ML - решает следующую задачу
Требуется подогнать заданный набор точек данными под соответствующую функцию (отображение входа на выход),
которая улавливает важные сигналы в данных и игнорирует помехи, а затем убедиться, что на новых данных функция работает хорошо.
"""

# Обучение с учителем (supervised learning)
"""
ОчУ - моделирует отношение между признаками и метками. Такие модели служат для предсказания меток на основе обучающих данных маркированных.
После построения модели можно использовать ее для присвоения меток новым ранее неизвестным данным

- задачи классификации (метки - дискретные: два или более)
- задачи регрессии (метки/результат; непрерывные величины)
"""

# Обучение без учителя (unsupervised learning)
"""
ОбУ = моделирование признаки без меток. Такие модели служат для выявления структуры немаркированных данных.

- задача кластеризации (выделяет отдельные группы данных)
- понижения размерности (поиск более сжатого представления данных)
"""

# Существуют методы частичного обучения (semi-supervised learning). Не все данны промаркированы

# Методы обучения с подкреплением (reinforcement learning). Система обучения улучшает свои характеристики на основе взаимодействия 
# (обратной связи) со средой. При этом взаимдействии система получает сигналы (функции наград), которые несут в себе информацию
# насколько хорошо/плохо система решила задачу (с точки зрения среды). Итоговая награда не станет максимальной.

import seaborn as sns

iris = sns.load_dataset("iris")
print(iris.head())
print(type(iris))

print(type(iris.values))
print(type(iris.shape))

print(iris.values.shape)
print(iris.columns)
print(iris.index)

"""
Строка - отдельные объекты - образцы (sample)
Столбцы - признаки - соответствуют конкретным наблюдениям (feature)
Матрица признаков (feature matrix). Размер матрица - [число образцов х число признаков]
Целевой массив, массив меток (targets) - одномерный массив [1 х число образцов] - данные которые мы хотим предсказать на основе имеющихся данных

Зависимые (метка) и независимые переменные (признаки)
"""

# Процесс построения системы машинного обучения:
"""
1. Предварительная обработка:
1.1. На вход поступают необработанные данные и метки
1.2. Происходит выбор признаков, масштабирование признаков
1.3. Понижение размерности
1.4. Происзодит выборка образцов
1.5. На выход набор данных: обучающий и тестовый
Обучающий далее идет на обучение, а на тестовом смотрим результат работы
2. Обучение:
2.1. Выбор модели
2.2. Перекрестная проверка
2.3. Метрики эффиктивности
2.4. Оптимизация гиперпараметров. Гиперпараметры - параметры, которые получаются не из данных, а являются настраиваемыми характеристиками модели
3. Оценка и формирование финальной модели
4. Прогнозирование (использование модели)
"""

# SciKit-learn - библиотека используемая

"""
1. Выбираем класс модели
2. Устанавливаем гиперпараметры модели
3. Создаем матрицу признаков и целевой массив
4. Обучение модели fit()
5. Применять модель к новым данным:
- predict() (с учителем)
- predict() или transform() (без учителя)
"""

# Обучение с учителем: Линейная регрессия
"""
Простая линейная регрессия
y = a * x + b
"""

import matplotlib.pyplot as plt
import numpy as np

np.random.seed(1)
x = 10 * np.random.rand(50)

y = 2 * x + np.random.randn(50)

plt.scatter(x, y)

# II
# 1. Выбираем класс модели
from sklearn.linear_model import LinearRegression

# 2. Устанавливаем гиперпараметры модели
model = LinearRegression(
    fit_intercept=True,
)

# 3. Создаем матрицу признаков и целевой массив

# 4. Обучение модели fit()
X = x[:, np.newaxis]

model.fit(X, y)

print(model.coef_[0])          # коэффициент a
print(model.intercept_)     # коэффициент b

x_ = np.linspace(0, 10, 30)
y_ = model.coef_[0] * x_ + model.intercept_
plt.plot(x_, y_)


# 5. Применять модель к новым данным

xfit = np.linspace(-10, 10, 5)
yfit = model.predict(xfit[:, np.newaxis])

plt.scatter(xfit, yfit)

plt.show()
